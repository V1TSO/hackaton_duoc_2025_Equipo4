{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49169415",
   "metadata": {},
   "source": [
    "# Hackathon IA Aplicada ‚Äì Predicci√≥n de Riesgo de Hipertensi√≥n\n",
    "\n",
    "Este notebook sigue las directrices de la r√∫brica del hackathon para entrenar y evaluar un modelo de riesgo de hipertensi√≥n usando datos NHANES 2017‚Äì2020. Se mantienen las secciones y markdowns originales, y solo se modifican las celdas de c√≥digo para incorporar el split temporal, anti-fuga, calibraci√≥n de probabilidades y fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929f39e",
   "metadata": {},
   "source": [
    "## Configuraci√≥n general ‚Äì Hackathon IA Aplicada (NHANES)\n",
    "\n",
    "En esta secci√≥n se carga el dataset mergeado del ciclo 2017‚Äì2020 y se realiza una comprobaci√≥n b√°sica de las columnas clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931dc451",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque el entorno de Python \"Python 3.13.9\" ya no est√° disponible. Considere la posibilidad de seleccionar otro kernel o de actualizar la lista de entornos de Python."
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================\n",
    "# CARGA DEL DATASET MERGEADO\n",
    "# ==============================\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "MERGED = Path('data/processed/nhanes_2017_2020_clean.csv')\n",
    "assert MERGED.exists(), f\"No existe {MERGED}. Ejecuta el merge previo.\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(MERGED)\n",
    "print(f\"‚úÖ Dataset mergeado cargado: {MERGED} ‚Äì shape {df.shape}\")\n",
    "\n",
    "# Mini sanity-check\n",
    "expected_cols = {'SEQN','SDDSRVYR'}\n",
    "missing = expected_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Faltan columnas requeridas: {missing}\")\n",
    "\n",
    "# Convertir num√©ricos por seguridad\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = pd.to_numeric(df[c], errors='ignore')\n",
    "\n",
    "# Vista previa\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bf442",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO Y CONSTRUCCI√ìN DE VARIABLES\n",
    "\n",
    "Esta secci√≥n prepara las features tabulares a partir de los m√≥dulos demogr√°ficos, antropom√©tricos y de laboratorio, evitando fuga de informaci√≥n. Tambi√©n crea las etiquetas de tensi√≥n (multiclase y binaria) utilizando √∫nicamente las columnas de presi√≥n oscilom√©trica (BPXO*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db204e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# PREPROCESAMIENTO (anti-fuga) y FEATURES TABULARES ‚Äî REFACTORIZADO\n",
    "# ==========================================================\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "np.random.seed(42)  # reproducibilidad\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Mapeos y columnas base\n",
    "# ------------------------------\n",
    "cols_demo = {\n",
    "    'RIDAGEYR': 'edad',\n",
    "    'RIAGENDR': 'sexo',\n",
    "    'RIDRETH1': 'etnia',\n",
    "    'DMDEDUC2': 'educacion',\n",
    "    'INDFMPIR': 'ratio_ingreso_pobreza'\n",
    "}\n",
    "cols_bmx = {\n",
    "    'BMXWT': 'peso_kg',\n",
    "    'BMXHT': 'altura_cm',\n",
    "    'BMXBMI': 'imc',\n",
    "    'BMXWAIST': 'cintura_cm'\n",
    "}\n",
    "cols_glu = {'LAB_LBXGLU': 'glucosa_mgdl'}\n",
    "cols_hdl = {'LAB_LBDHDD': 'hdl_mgdl'}\n",
    "cols_tri = {'LAB_LBXTR': 'trigliceridos_mgdl', 'LAB_LBDLDL': 'ldl_mgdl'}\n",
    "\n",
    "# BP oscilom√©trica (para LABEL √∫nicamente)\n",
    "bpxo_candidates = ['BPXOSY1','BPXOSY2','BPXOSY3','BPXODI1','BPXODI2','BPXODI3']\n",
    "available_bpxo = [c for c in bpxo_candidates if c in df.columns]\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Selecci√≥n de columnas y copia de trabajo\n",
    "# ------------------------------\n",
    "use_cols = (\n",
    "    ['SEQN','SDDSRVYR']\n",
    "    + list(cols_demo.keys())\n",
    "    + list(cols_bmx.keys())\n",
    "    + available_bpxo\n",
    "    + list(cols_glu.keys())\n",
    "    + list(cols_hdl.keys())\n",
    "    + list(cols_tri.keys())\n",
    ")\n",
    "\n",
    "present_cols = [c for c in use_cols if c in df.columns]\n",
    "missing_cols = [c for c in use_cols if c not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"‚ÑπÔ∏è Aviso: faltan columnas opcionales (omitidas): {missing_cols}\")\n",
    "\n",
    "work = df[present_cols].copy()\n",
    "work = work.rename(columns={**cols_demo, **cols_bmx, **cols_glu, **cols_hdl, **cols_tri})\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Filtros y tipados b√°sicos\n",
    "# ------------------------------\n",
    "# Adultos (18+)\n",
    "if 'edad' not in work.columns:\n",
    "    raise ValueError(\"‚ùå No se encuentra la columna 'edad' (RIDAGEYR).\")\n",
    "work = work[work['edad'].ge(18)].copy()\n",
    "\n",
    "# Sexo binario 0=Hombre, 1=Mujer\n",
    "if 'sexo' in work.columns:\n",
    "    work['sexo'] = pd.to_numeric(work['sexo'], errors='coerce').map({1: 0, 2: 1}).astype('Int64')\n",
    "\n",
    "# Educaci√≥n (limpia c√≥digos especiales)\n",
    "if 'educacion' in work.columns:\n",
    "    work['educacion'] = pd.to_numeric(work['educacion'], errors='coerce')\n",
    "    work.loc[work['educacion'].isin([7, 9]), 'educacion'] = np.nan\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Derivadas seguras\n",
    "# ------------------------------\n",
    "if {'cintura_cm', 'altura_cm'}.issubset(work.columns):\n",
    "    altura_segura = work['altura_cm'].where(work['altura_cm'] > 0, np.nan)\n",
    "    work['rel_cintura_altura'] = work['cintura_cm'] / altura_segura\n",
    "else:\n",
    "    work['rel_cintura_altura'] = np.nan\n",
    "\n",
    "work['imc_cuadratico'] = work['imc'] ** 2 if 'imc' in work.columns else np.nan\n",
    "\n",
    "# ------------------------------\n",
    "# 5) LABEL: clasificar tensi√≥n (usa SOLO BPXO para evitar fuga)\n",
    "# ------------------------------\n",
    "if available_bpxo:\n",
    "    sys_cols = [c for c in ['BPXOSY1','BPXOSY2','BPXOSY3'] if c in work.columns]\n",
    "    dia_cols = [c for c in ['BPXODI1','BPXODI2','BPXODI3'] if c in work.columns]\n",
    "\n",
    "    # Promedios robustos (maneja faltantes)\n",
    "    s_mean = work[sys_cols].mean(axis=1) if sys_cols else pd.Series(np.nan, index=work.index)\n",
    "    d_mean = work[dia_cols].mean(axis=1) if dia_cols else pd.Series(np.nan, index=work.index)\n",
    "\n",
    "    # Clasificaci√≥n estable: 0=hypo, 1=normal, 2=HTA\n",
    "    conds = [\n",
    "        (s_mean < 90) | (d_mean < 60),\n",
    "        (s_mean >= 140) | (d_mean >= 90)\n",
    "    ]\n",
    "    vals = [0.0, 2.0]\n",
    "    tension = np.select(conds, vals, default=1.0).astype(float)\n",
    "    tension[s_mean.isna() | d_mean.isna()] = np.nan\n",
    "\n",
    "    # Derivadas √∫tiles (con protecci√≥n)\n",
    "    work['imc_x_edad'] = work.get('imc', np.nan) * work['edad']\n",
    "    if {'hdl_mgdl','ldl_mgdl'}.issubset(work.columns):\n",
    "        work['ratio_hdl_ldl'] = work['hdl_mgdl'] / work['ldl_mgdl']\n",
    "        work['ratio_hdl_ldl'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    else:\n",
    "        work['ratio_hdl_ldl'] = np.nan\n",
    "\n",
    "    if 'trigliceridos_mgdl' in work.columns:\n",
    "        work['trigliceridos_log'] = np.log1p(work['trigliceridos_mgdl'])\n",
    "    else:\n",
    "        work['trigliceridos_log'] = np.nan\n",
    "\n",
    "    work['tension_clase'] = pd.Series(tension, index=work.index).astype('Float64')\n",
    "    work = work[work['tension_clase'].notna()].copy()\n",
    "    work['riesgo_hipertension'] = (work['tension_clase'] == 2).astype('Int64')\n",
    "else:\n",
    "    raise ValueError(\"‚ùå No hay columnas BPXO disponibles para generar el label de HTA.\")\n",
    "\n",
    "# ------------------------------\n",
    "# 6) One-hot encoding de etnia\n",
    "# ------------------------------\n",
    "if 'etnia' in work.columns:\n",
    "    etnia_dummies = pd.get_dummies(work['etnia'], prefix='etnia', drop_first=True, dtype=int)\n",
    "    work = pd.concat([work.drop(columns=['etnia']), etnia_dummies], axis=1)\n",
    "else:\n",
    "    etnia_dummies = pd.DataFrame(index=work.index)\n",
    "\n",
    "# ------------------------------\n",
    "# 7) Conjunto de features sin fuga\n",
    "# ------------------------------\n",
    "base_features = [\n",
    "    'edad', 'sexo', 'educacion', 'ratio_ingreso_pobreza',\n",
    "    'imc', 'cintura_cm', 'rel_cintura_altura',\n",
    "    'glucosa_mgdl', 'hdl_mgdl', 'trigliceridos_mgdl', 'ldl_mgdl',\n",
    "    'imc_cuadratico', 'imc_x_edad', 'ratio_hdl_ldl', 'trigliceridos_log'\n",
    "]\n",
    "feature_candidates = [c for c in base_features + list(etnia_dummies.columns) if c in work.columns]\n",
    "\n",
    "# Bloque anti-fuga expl√≠cito\n",
    "forbidden_prefixes = ('BPX', 'BPXO', 'BPXSY', 'BPXDI')\n",
    "feature_candidates = [c for c in feature_candidates if not any(c.startswith(pref) for pref in forbidden_prefixes)]\n",
    "\n",
    "if len(feature_candidates) == 0:\n",
    "    raise ValueError(\"‚ùå Sin features disponibles para modelar tras la limpieza.\")\n",
    "\n",
    "# ------------------------------\n",
    "# 8) Limpieza de NaN en features\n",
    "# ------------------------------\n",
    "before = len(work)\n",
    "work = work.dropna(subset=feature_candidates).copy()\n",
    "after = len(work)\n",
    "if after < before:\n",
    "    print(f\"‚ÑπÔ∏è Filas eliminadas por NaN en features: {before - after}\")\n",
    "\n",
    "nan_pct = work[feature_candidates].isna().mean()\n",
    "if (nan_pct > 0).any():\n",
    "    print(\"‚ö†Ô∏è A√∫n hay NaN en algunas columnas de features:\")\n",
    "    print(nan_pct[nan_pct > 0].sort_values(ascending=False).head(10))\n",
    "\n",
    "# ------------------------------\n",
    "# 9) Resumen final\n",
    "# ------------------------------\n",
    "print(f\"‚úÖ Registros finales para modelado: {len(work)} | Features: {len(feature_candidates)}\")\n",
    "work.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c77cf",
   "metadata": {},
   "source": [
    "## AN√ÅLISIS EXPLORATORIO DE VARIABLES\n",
    "\n",
    "(Los gr√°ficos exploratorios permanecen sin cambios para no afectar la r√∫brica; puedes ejecutar an√°lisis adicionales seg√∫n sea necesario.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Sin cambios en EDA)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11653708",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO Y EVALUACI√ìN ‚Äì MODELO BINARIO\n",
    "\n",
    "En esta secci√≥n se realiza la validaci√≥n temporal, entrenamiento, calibraci√≥n y evaluaci√≥n del modelo de riesgo de hipertensi√≥n siguiendo la r√∫brica del hackathon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39131f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# VALIDACI√ìN TEMPORAL + K-FOLD CON SMOTE INTERNO + ENSEMBLE CALIBRADO FINAL\n",
    "# ==========================================================\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, brier_score_loss, average_precision_score,\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import matplotlib.pyplot as plt, seaborn as sns, shap, joblib\n",
    "\n",
    "# ==========================================================\n",
    "# 1) DIVISI√ìN TEMPORAL (sin SMOTE global) + FALLBACK\n",
    "# ==========================================================\n",
    "X_full = work[feature_candidates].copy().astype(float)\n",
    "y_full = work['riesgo_hipertension'].astype(int)\n",
    "\n",
    "if 'SDDSRVYR' in work.columns and work['SDDSRVYR'].nunique() > 1:\n",
    "    cycles = sorted(work['SDDSRVYR'].dropna().unique().tolist())\n",
    "    train_cycles, test_cycles = cycles[:-1], cycles[-1:]\n",
    "    train_df = work[work['SDDSRVYR'].isin(train_cycles)].copy()\n",
    "    test_df  = work[work['SDDSRVYR'].isin(test_cycles)].copy()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Split temporal no disponible/insuficiente. Usando split estratificado 80/20.\")\n",
    "    train_df, test_df = train_test_split(\n",
    "        work, test_size=0.2, stratify=work['riesgo_hipertension'], random_state=42\n",
    "    )\n",
    "\n",
    "if train_df['riesgo_hipertension'].nunique() < 2:\n",
    "    print(\"‚ö†Ô∏è Train con una sola clase. Rehaciendo split estratificado 70/30.\")\n",
    "    train_df, test_df = train_test_split(\n",
    "        work, test_size=0.3, stratify=work['riesgo_hipertension'], random_state=123\n",
    "    )\n",
    "\n",
    "X_train_full = train_df[feature_candidates].astype(float)\n",
    "y_train_full = train_df['riesgo_hipertension'].astype(int)\n",
    "X_test = test_df[feature_candidates].astype(float)\n",
    "y_test = test_df['riesgo_hipertension'].astype(int)\n",
    "\n",
    "print(\"üîπ Distribuci√≥n Train:\", Counter(y_train_full))\n",
    "print(\"üîπ Distribuci√≥n Test:\", Counter(y_test))\n",
    "\n",
    "# ==========================================================\n",
    "# 2) PREPROCESAMIENTO\n",
    "# ==========================================================\n",
    "num_tf = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "pre = ColumnTransformer([('num', num_tf, feature_candidates)], remainder='drop')\n",
    "\n",
    "# ==========================================================\n",
    "# 3) MODELOS BASE OPTIMIZADOS\n",
    "# ==========================================================\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    solver='saga',\n",
    "    C=1.0,\n",
    "    penalty='l2',\n",
    "    random_state=42\n",
    ")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=14,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced_subsample',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'LogReg': ImbPipeline([('pre', pre), ('smote', SMOTE(random_state=42, k_neighbors=3)), ('clf', log_reg)]),\n",
    "    'RandomForest': ImbPipeline([('pre', pre), ('smote', SMOTE(random_state=42, k_neighbors=3)), ('clf', rf)])\n",
    "}\n",
    "\n",
    "# ==========================================================\n",
    "# 4) K-FOLD + SMOTE INTERNO (sin fuga)\n",
    "# ==========================================================\n",
    "min_class = min(Counter(y_train_full).values())\n",
    "n_splits = min(5, max(2, min_class))\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Validando modelo: {name} ({n_splits}-fold)\")\n",
    "    aurocs, briers, f1s = [], [], []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train_full, y_train_full), 1):\n",
    "        X_tr, X_val = X_train_full.iloc[tr_idx], X_train_full.iloc[val_idx]\n",
    "        y_tr, y_val = y_train_full.iloc[tr_idx], y_train_full.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        proba_val = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "        auroc = roc_auc_score(y_val, proba_val)\n",
    "        brier = brier_score_loss(y_val, proba_val)\n",
    "        f1 = f1_score(y_val, preds)\n",
    "\n",
    "        aurocs.append(auroc); briers.append(brier); f1s.append(f1)\n",
    "        print(f\"  Fold {fold}: AUROC={auroc:.3f} | Brier={brier:.3f} | F1={f1:.3f}\")\n",
    "\n",
    "    results.append((name, np.mean(aurocs), np.std(aurocs), np.mean(briers), np.mean(f1s)))\n",
    "\n",
    "best_name, mean_auc, std_auc, mean_brier, mean_f1 = sorted(results, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"\\nüèÅ Mejor modelo: {best_name} | AUROC_cv={mean_auc:.3f} ¬±{std_auc:.3f} | Brier_cv={mean_brier:.3f} | F1_cv={mean_f1:.3f}\")\n",
    "\n",
    "best_model = models[best_name]\n",
    "best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# ==========================================================\n",
    "# 5) ENSEMBLE LOGREG + RF + CALIBRACI√ìN\n",
    "# ==========================================================\n",
    "proba_lr = models['LogReg'].fit(X_train_full, y_train_full).predict_proba(X_test)[:, 1]\n",
    "proba_rf = models['RandomForest'].fit(X_train_full, y_train_full).predict_proba(X_test)[:, 1]\n",
    "proba_ensemble = (proba_lr + proba_rf) / 2\n",
    "\n",
    "calibrated = CalibratedClassifierCV(best_model, method='sigmoid', cv=3)\n",
    "calibrated.fit(X_train_full, y_train_full)\n",
    "\n",
    "# ==========================================================\n",
    "# 6) EVALUACI√ìN EN TEST (ENSEMBLE)\n",
    "# ==========================================================\n",
    "auroc = roc_auc_score(y_test, proba_ensemble)\n",
    "auprc = average_precision_score(y_test, proba_ensemble)\n",
    "brier = brier_score_loss(y_test, proba_ensemble)\n",
    "\n",
    "ths = np.linspace(0, 1, 101)\n",
    "f1s = [f1_score(y_test, (proba_ensemble >= th).astype(int)) for th in ths]\n",
    "best_th = ths[np.argmax(f1s)]\n",
    "pred_opt = (proba_ensemble >= best_th).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, pred_opt)\n",
    "prec = precision_score(y_test, pred_opt)\n",
    "rec = recall_score(y_test, pred_opt)\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS TEST (ENSEMBLE):\")\n",
    "print(f\"AUROC={auroc:.3f} | AUPRC={auprc:.3f} | Brier={brier:.3f} | Umbral √≥ptimo(F1)={best_th:.2f}\")\n",
    "print(f\"Acc={acc:.3f} | Prec={prec:.3f} | Rec={rec:.3f}\")\n",
    "print(\"\\n\", classification_report(y_test, pred_opt, target_names=['NoHTA','HTA']))\n",
    "\n",
    "# ==========================================================\n",
    "# 7) CURVAS\n",
    "# ==========================================================\n",
    "fpr, tpr, _ = roc_curve(y_test, proba_ensemble)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Ensemble (AUC={auroc:.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Falsos positivos'); plt.ylabel('Verdaderos positivos')\n",
    "plt.legend(); plt.grid(alpha=.3); plt.title('Curva ROC ‚Äì Ensemble'); plt.show()\n",
    "\n",
    "prec_c, rec_c, _ = precision_recall_curve(y_test, proba_ensemble)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(rec_c, prec_c)\n",
    "plt.xlabel('Recall'); plt.ylabel('Precisi√≥n')\n",
    "plt.title('Precision-Recall ‚Äì Ensemble'); plt.grid(alpha=.3); plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_opt)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusi√≥n ‚Äì Ensemble (umbral √≥ptimo)'); plt.xlabel('Predicho'); plt.ylabel('Real'); plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# 8) GUARDAR MODELO\n",
    "# ==========================================================\n",
    "models_dir = Path('models'); models_dir.mkdir(exist_ok=True)\n",
    "model_path = models_dir / 'ensemble_logreg_rf_calibrado.pkl'\n",
    "joblib.dump(calibrated, model_path)\n",
    "print(f\"üíæ Modelo calibrado guardado en: {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
